{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33771573-05df-4109-86b9-878babc0cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import flwr as fl\n",
    "# Load and compile Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf75d36-4a17-4f41-85c0-f8b9cb06791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c156b7-afe0-4c69-aaa0-56c0f195c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_data_dir = 'D:/TQ/Balanced_Another/Client1/train/'\n",
    "\n",
    "test_data_dir = 'D:/TQ/Balanced_Another/Client1/val/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa64b10-7877-477a-8c9e-6441a3ef7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Set the validation split percentage\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fb633-e595-4a3c-861a-a09b99386696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts in Training Samples:\n",
      "['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
      "Animal_Abuse: 124 samples\n",
      "Arson: 0 samples\n",
      "Fight: 342 samples\n",
      "Normal: 199 samples\n",
      "Riot: 253 samples\n",
      "Traffic_Accident: 179 samples\n",
      "Train_Accident: 150 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Counts in Training Samples:\")\n",
    "total_classes = sorted(os.listdir(train_data_dir))\n",
    "print(total_classes)\n",
    "for category in total_classes:\n",
    "    category_path = os.path.join(train_data_dir, category)\n",
    "    sample_count = len(os.listdir(category_path))\n",
    "    print(f\"{category}: {sample_count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a147d6-0056-4cf8-ac6a-abb71e30c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = sorted(os.listdir(train_data_dir))\n",
    "test_classes = sorted(os.listdir(test_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64b577db-0e07-4e6a-b627-21b571271f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout layer with a dropout rate of 0.5\n",
    "outputs = Dense(7, activation='softmax')(x)  # Assuming binary classification\n",
    "\n",
    "# Create the full model\n",
    "model1 = Model(inputs, outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model1.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ce4684-b004-4235-9a7d-ed6d371a020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1001 images belonging to 7 classes.\n",
      "Found 246 images belonging to 7 classes.\n",
      "Found 349 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(225, 225),\n",
    "                                                   class_mode='categorical',\n",
    "                                                   classes=total_classes,\n",
    "                                                   subset='training',\n",
    "                                                   batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42)\n",
    "\n",
    "validgen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(225, 225),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=total_classes,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(225, 225),\n",
    "                                             class_mode='categorical',\n",
    "                                             classes=total_classes,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "053e9f4e-6c00-4526-aa6b-1d6a941f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e0e1c1d-7cad-4e48-a3aa-a0ee579a7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "126/126 [==============================] - 34s 250ms/step - loss: 0.7874 - accuracy: 0.7423 - val_loss: 1.4294 - val_accuracy: 0.5366\n",
      "Epoch 2/5\n",
      "126/126 [==============================] - 30s 238ms/step - loss: 0.1922 - accuracy: 0.9371 - val_loss: 1.8712 - val_accuracy: 0.5488\n",
      "Epoch 3/5\n",
      "126/126 [==============================] - 28s 219ms/step - loss: 0.1534 - accuracy: 0.9600 - val_loss: 2.1121 - val_accuracy: 0.5610\n",
      "Epoch 4/5\n",
      "126/126 [==============================] - 28s 220ms/step - loss: 0.1081 - accuracy: 0.9690 - val_loss: 2.3302 - val_accuracy: 0.5366\n",
      "Epoch 5/5\n",
      "126/126 [==============================] - 30s 239ms/step - loss: 0.0746 - accuracy: 0.9820 - val_loss: 2.2035 - val_accuracy: 0.5650\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(\n",
    "            traingen,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(traingen),\n",
    "            validation_data=validgen,\n",
    "            validation_steps=len(validgen),\n",
    "            callbacks=callbacks,\n",
    "            verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fa7933e-0d68-4f34-8243-6481173c5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"Client1_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc89279f-832a-498d-b009-ee7f8bfa08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 9s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = model1.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbf942fb-108b-4952-86ea-5e442dc3a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Test Loss: 1.4517643451690674\n",
      "Test Accuracy: 0.8280802369117737\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "test_loss, test_accuracy = model.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76ee29f4-21fb-4c83-9c07-b185fb881694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[30  0  0  1  0  0  0]\n",
      " [ 0  0  0 25  0 10  0]\n",
      " [ 0  0 73 13  0  0  0]\n",
      " [ 0  0  0 43  0  6  1]\n",
      " [ 0  0  0  0 64  0  0]\n",
      " [ 0  0  0  4  0 41  0]\n",
      " [ 0  0  0  0  0  0 38]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c104591d-a047-48f8-978d-a0a649435ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm2, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix1.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1759984-7d01-46f2-9134-13361b238461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Client1_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe698752-28ee-407b-9dde-7ce095a33e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.97      0.98        31\n",
      "           Arson       1.00      0.46      0.63        35\n",
      "           Fight       1.00      0.85      0.92        86\n",
      "          Normal       0.59      0.90      0.71        50\n",
      "            Riot       1.00      1.00      1.00        64\n",
      "Traffic_Accident       0.82      1.00      0.90        45\n",
      "  Train_Accident       1.00      0.92      0.96        38\n",
      "\n",
      "        accuracy                           0.88       349\n",
      "       macro avg       0.92      0.87      0.87       349\n",
      "    weighted avg       0.92      0.88      0.88       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddd53fd-42a2-4313-940b-7b66368ddc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "client1 = tf.keras.models.load_model('D:/TQ/Balanced_Another/client1_30_rounds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62914688-50aa-4259-86b1-ecf59a31b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 11s 24ms/step\n",
      "Test Loss: 0.8237746357917786\n",
      "Test Accuracy: 0.8911174535751343\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.97      0.98        31\n",
      "           Arson       1.00      0.57      0.73        35\n",
      "           Fight       1.00      0.85      0.92        86\n",
      "          Normal       0.58      0.90      0.71        50\n",
      "            Riot       1.00      1.00      1.00        64\n",
      "Traffic_Accident       0.90      1.00      0.95        45\n",
      "  Train_Accident       1.00      0.92      0.96        38\n",
      "\n",
      "        accuracy                           0.89       349\n",
      "       macro avg       0.93      0.89      0.89       349\n",
      "    weighted avg       0.93      0.89      0.90       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = client1.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels\n",
    "test_loss, test_accuracy = client1.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "232430ab-4562-45ab-b5b5-49211706744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix After Aggregation:\n",
      "[[30  0  0  1  0  0  0]\n",
      " [ 0 20  0 15  0  0  0]\n",
      " [ 0  0 73 13  0  0  0]\n",
      " [ 0  0  0 45  0  5  0]\n",
      " [ 0  0  0  0 64  0  0]\n",
      " [ 0  0  0  0  0 45  0]\n",
      " [ 0  0  0  3  0  0 35]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix After Aggregation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d91f3e6-8bfa-4a18-9735-f5564994d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix1f.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17c2c0-3630-4210-92c6-749d070be2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30283579-398f-471f-a4ac-064e25af1108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
