{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33771573-05df-4109-86b9-878babc0cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import flwr as fl\n",
    "# Load and compile Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf75d36-4a17-4f41-85c0-f8b9cb06791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c156b7-afe0-4c69-aaa0-56c0f195c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_data_dir = 'D:/TQ/Federated/1/train/'\n",
    "\n",
    "test_data_dir = 'D:/TQ/Federated/1/val/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa64b10-7877-477a-8c9e-6441a3ef7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Set the validation split percentage\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fb633-e595-4a3c-861a-a09b99386696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts in Training Samples:\n",
      "['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
      "Animal_Abuse: 124 samples\n",
      "Arson: 80 samples\n",
      "Fight: 320 samples\n",
      "Normal: 199 samples\n",
      "Riot: 251 samples\n",
      "Traffic_Accident: 160 samples\n",
      "Train_Accident: 440 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Counts in Training Samples:\")\n",
    "total_classes = sorted(os.listdir(train_data_dir))\n",
    "print(total_classes)\n",
    "for category in total_classes:\n",
    "    category_path = os.path.join(train_data_dir, category)\n",
    "    sample_count = len(os.listdir(category_path))\n",
    "    print(f\"{category}: {sample_count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a147d6-0056-4cf8-ac6a-abb71e30c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = sorted(os.listdir(train_data_dir))\n",
    "test_classes = sorted(os.listdir(test_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b577db-0e07-4e6a-b627-21b571271f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout layer with a dropout rate of 0.5\n",
    "outputs = Dense(7, activation='softmax')(x)  # Assuming binary classification\n",
    "\n",
    "# Create the full model\n",
    "model1 = Model(inputs, outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model1.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ce4684-b004-4235-9a7d-ed6d371a020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1261 images belonging to 7 classes.\n",
      "Found 313 images belonging to 7 classes.\n",
      "Found 360 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(225, 225),\n",
    "                                                   class_mode='categorical',\n",
    "                                                   classes=total_classes,\n",
    "                                                   subset='training',\n",
    "                                                   batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42)\n",
    "\n",
    "validgen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(225, 225),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=total_classes,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(225, 225),\n",
    "                                             class_mode='categorical',\n",
    "                                             classes=total_classes,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e9f4e-6c00-4526-aa6b-1d6a941f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0e1c1d-7cad-4e48-a3aa-a0ee579a7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 [==============================] - 52s 305ms/step - loss: 0.8215 - accuracy: 0.7193 - val_loss: 1.3026 - val_accuracy: 0.6102\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 29s 183ms/step - loss: 0.2309 - accuracy: 0.9318 - val_loss: 1.6398 - val_accuracy: 0.6454\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 28s 178ms/step - loss: 0.1392 - accuracy: 0.9564 - val_loss: 1.8614 - val_accuracy: 0.6358\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 27s 170ms/step - loss: 0.1032 - accuracy: 0.9730 - val_loss: 2.0864 - val_accuracy: 0.6422\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 27s 172ms/step - loss: 0.0882 - accuracy: 0.9794 - val_loss: 1.9256 - val_accuracy: 0.6677\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(\n",
    "            traingen,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(traingen),\n",
    "            validation_data=validgen,\n",
    "            validation_steps=len(validgen),\n",
    "            callbacks=callbacks,\n",
    "            verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fa7933e-0d68-4f34-8243-6481173c5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"Client1_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc89279f-832a-498d-b009-ee7f8bfa08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 9s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = model1.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbf942fb-108b-4952-86ea-5e442dc3a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3338848650455475\n",
      "Test Accuracy: 0.9388889074325562\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "test_loss, test_accuracy = model1.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76ee29f4-21fb-4c83-9c07-b185fb881694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[28  0  0  3  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0 67 13  0  0  0]\n",
      " [ 0  0  0 45  0  5  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 0  0  0  0  0 41  0]\n",
      " [ 0  0  0 21  0  6 48]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c104591d-a047-48f8-978d-a0a649435ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm2, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix1.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe698752-28ee-407b-9dde-7ce095a33e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.90      0.95        31\n",
      "           Arson       1.00      1.00      1.00        20\n",
      "           Fight       1.00      0.84      0.91        80\n",
      "          Normal       0.55      0.90      0.68        50\n",
      "            Riot       1.00      1.00      1.00        63\n",
      "Traffic_Accident       0.79      1.00      0.88        41\n",
      "  Train_Accident       1.00      0.64      0.78        75\n",
      "\n",
      "        accuracy                           0.87       360\n",
      "       macro avg       0.91      0.90      0.89       360\n",
      "    weighted avg       0.91      0.87      0.87       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "911e1852-65ea-46fe-a20b-91f83d680584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 28, Total Instances: 31\n",
      "Arson - True Positives: 20, Total Instances: 20\n",
      "Fight - True Positives: 67, Total Instances: 80\n",
      "Normal - True Positives: 45, Total Instances: 50\n",
      "Riot - True Positives: 63, Total Instances: 63\n",
      "Traffic_Accident - True Positives: 41, Total Instances: 41\n",
      "Train_Accident - True Positives: 48, Total Instances: 75\n",
      "{'Animal_Abuse': 0.9032258064516129, 'Arson': 1.0, 'Fight': 0.8375, 'Normal': 0.9, 'Riot': 1.0, 'Traffic_Accident': 1.0, 'Train_Accident': 0.64}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm2[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1759984-7d01-46f2-9134-13361b238461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"Client1_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ddd53fd-42a2-4313-940b-7b66368ddc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "client1 = tf.keras.models.load_model('D:/TQ/Federated/client1_30_fedavg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62914688-50aa-4259-86b1-ecf59a31b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 8s 20ms/step\n",
      "Test Loss: 0.5148042440414429\n",
      "Test Accuracy: 0.8916666507720947\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.90      0.95        31\n",
      "           Arson       1.00      1.00      1.00        20\n",
      "           Fight       1.00      0.84      0.91        80\n",
      "          Normal       0.55      0.90      0.68        50\n",
      "            Riot       1.00      1.00      1.00        63\n",
      "Traffic_Accident       0.79      1.00      0.88        41\n",
      "  Train_Accident       1.00      0.64      0.78        75\n",
      "\n",
      "        accuracy                           0.87       360\n",
      "       macro avg       0.91      0.90      0.89       360\n",
      "    weighted avg       0.91      0.87      0.87       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = client1.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels\n",
    "test_loss, test_accuracy = client1.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "232430ab-4562-45ab-b5b5-49211706744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix After Aggregation:\n",
      "[[28  0  0  3  0  0  0]\n",
      " [ 0 20  0  0  0  0  0]\n",
      " [ 0  0 67 13  0  0  0]\n",
      " [ 0  0  0 45  0  5  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 0  0  0  0  0 41  0]\n",
      " [ 0  0  0 21  0  6 48]]\n"
     ]
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix After Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d91f3e6-8bfa-4a18-9735-f5564994d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix1f.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f17c2c0-3630-4210-92c6-749d070be2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 30, Total Instances: 31\n",
      "Arson - True Positives: 20, Total Instances: 20\n",
      "Fight - True Positives: 68, Total Instances: 80\n",
      "Normal - True Positives: 44, Total Instances: 50\n",
      "Riot - True Positives: 63, Total Instances: 63\n",
      "Traffic_Accident - True Positives: 41, Total Instances: 41\n",
      "Train_Accident - True Positives: 52, Total Instances: 75\n",
      "{'Animal_Abuse': 0.967741935483871, 'Arson': 1.0, 'Fight': 0.85, 'Normal': 0.88, 'Riot': 1.0, 'Traffic_Accident': 1.0, 'Train_Accident': 0.6933333333333334}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30283579-398f-471f-a4ac-064e25af1108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animal_Abuse': 0.9916666666666667, 'Arson': 1.0, 'Fight': 0.9638888888888889, 'Normal': 0.8944444444444445, 'Riot': 1.0, 'Traffic_Accident': 0.975, 'Train_Accident': 0.925}\n"
     ]
    }
   ],
   "source": [
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e3cfb-a666-49c9-9db9-0789ffa6b13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
