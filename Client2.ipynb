{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33771573-05df-4109-86b9-878babc0cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import flwr as fl\n",
    "# Load and compile Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf75d36-4a17-4f41-85c0-f8b9cb06791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c156b7-afe0-4c69-aaa0-56c0f195c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_data_dir = 'D:/TQ/Federated/2/train/'\n",
    "\n",
    "test_data_dir = 'D:/TQ/Federated/2/val/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa64b10-7877-477a-8c9e-6441a3ef7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Set the validation split percentage\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fb633-e595-4a3c-861a-a09b99386696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts in Training Samples:\n",
      "['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
      "Animal_Abuse: 192 samples\n",
      "Arson: 136 samples\n",
      "Fight: 240 samples\n",
      "Normal: 199 samples\n",
      "Riot: 253 samples\n",
      "Traffic_Accident: 200 samples\n",
      "Train_Accident: 176 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Counts in Training Samples:\")\n",
    "total_classes = sorted(os.listdir(train_data_dir))\n",
    "print(total_classes)\n",
    "for category in total_classes:\n",
    "    category_path = os.path.join(train_data_dir, category)\n",
    "    sample_count = len(os.listdir(category_path))\n",
    "    print(f\"{category}: {sample_count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a147d6-0056-4cf8-ac6a-abb71e30c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = sorted(os.listdir(train_data_dir))\n",
    "test_classes = sorted(os.listdir(test_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b577db-0e07-4e6a-b627-21b571271f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout layer with a dropout rate of 0.5\n",
    "outputs = Dense(7, activation='softmax')(x)  # Assuming binary classification\n",
    "\n",
    "# Create the full model\n",
    "model2 = Model(inputs, outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model2.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ce4684-b004-4235-9a7d-ed6d371a020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1119 images belonging to 7 classes.\n",
      "Found 277 images belonging to 7 classes.\n",
      "Found 351 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(225, 225),\n",
    "                                                   class_mode='categorical',\n",
    "                                                   classes=total_classes,\n",
    "                                                   subset='training',\n",
    "                                                   batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42)\n",
    "\n",
    "validgen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(225, 225),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=total_classes,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(225, 225),\n",
    "                                             class_mode='categorical',\n",
    "                                             classes=total_classes,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e9f4e-6c00-4526-aa6b-1d6a941f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0e1c1d-7cad-4e48-a3aa-a0ee579a7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 32s 208ms/step - loss: 0.9485 - accuracy: 0.6720 - val_loss: 0.4017 - val_accuracy: 0.8881\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 23s 161ms/step - loss: 0.2115 - accuracy: 0.9410 - val_loss: 0.4791 - val_accuracy: 0.8700\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.1170 - accuracy: 0.9705 - val_loss: 0.4578 - val_accuracy: 0.8664\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 26s 188ms/step - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.5397 - val_accuracy: 0.8628\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 27s 192ms/step - loss: 0.0628 - accuracy: 0.9857 - val_loss: 0.4979 - val_accuracy: 0.8592\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(\n",
    "            traingen,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(traingen),\n",
    "            validation_data=validgen,\n",
    "            validation_steps=len(validgen),\n",
    "            callbacks=callbacks,\n",
    "            verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186b3d72-1db7-44c3-b68d-178824f689c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"Client2_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc89279f-832a-498d-b009-ee7f8bfa08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 10s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = model2.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf942fb-108b-4952-86ea-5e442dc3a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Test Loss: 0.09722714871168137\n",
      "Test Accuracy: 0.9829059839248657\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "test_loss, test_accuracy = model2.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ee29f4-21fb-4c83-9c07-b185fb881694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[48  0  0  0  0  0  0]\n",
      " [ 0 35  0  0  0  0  0]\n",
      " [ 0  0 60  0  0  0  0]\n",
      " [ 0  0  0 45  0  5  0]\n",
      " [ 0  0  0  0 64  0  0]\n",
      " [ 0  0  0  0  0 50  0]\n",
      " [ 0  0  0  0  0  0 44]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dba96e8-9a2a-4a84-89e8-52fce5e1d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm2, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix2.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17fe4afc-0739-4369-9f4a-62229ee53a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animal_Abuse': 1.0, 'Arson': 1.0, 'Fight': 1.0, 'Normal': 0.9829059829059829, 'Riot': 1.0, 'Traffic_Accident': 0.98005698005698, 'Train_Accident': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    # True negatives are all the samples that are not our current GT class (not the current row) \n",
    "    # and were not predicted as the current class (not the current column)\n",
    "    true_negatives = np.sum(np.delete(np.delete(cm, idx, axis=0), idx, axis=1))\n",
    "    \n",
    "    # True positives are all the samples of our current GT class that were predicted as such\n",
    "    true_positives = cm2[idx, idx]\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = (true_positives + true_negatives) / np.sum(cm2)\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "564e88b2-831a-436c-a609-293a56377ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 48, Total Instances: 48\n",
      "Arson - True Positives: 35, Total Instances: 35\n",
      "Fight - True Positives: 60, Total Instances: 60\n",
      "Normal - True Positives: 45, Total Instances: 50\n",
      "Riot - True Positives: 64, Total Instances: 64\n",
      "Traffic_Accident - True Positives: 50, Total Instances: 50\n",
      "Train_Accident - True Positives: 44, Total Instances: 44\n",
      "{'Animal_Abuse': 1.0, 'Arson': 1.0, 'Fight': 1.0, 'Normal': 0.9, 'Riot': 1.0, 'Traffic_Accident': 1.0, 'Train_Accident': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm2[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm2[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1759984-7d01-46f2-9134-13361b238461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"Client2_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f341f304-c55d-4fef-a24a-9b461f66d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      1.00      1.00        48\n",
      "           Arson       1.00      1.00      1.00        35\n",
      "           Fight       1.00      1.00      1.00        60\n",
      "          Normal       1.00      0.90      0.95        50\n",
      "            Riot       1.00      1.00      1.00        64\n",
      "Traffic_Accident       0.91      1.00      0.95        50\n",
      "  Train_Accident       1.00      1.00      1.00        44\n",
      "\n",
      "        accuracy                           0.99       351\n",
      "       macro avg       0.99      0.99      0.99       351\n",
      "    weighted avg       0.99      0.99      0.99       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe698752-28ee-407b-9dde-7ce095a33e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "client2 = tf.keras.models.load_model('client2_30_fedavg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad0f1a5f-5148-4141-8737-adc11dd86a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 8s 22ms/step\n",
      "Test Loss: 0.16063350439071655\n",
      "Test Accuracy: 0.9715099930763245\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.98      0.99        48\n",
      "           Arson       1.00      1.00      1.00        35\n",
      "           Fight       1.00      1.00      1.00        60\n",
      "          Normal       0.98      0.90      0.94        50\n",
      "            Riot       1.00      1.00      1.00        64\n",
      "Traffic_Accident       0.88      1.00      0.93        50\n",
      "  Train_Accident       1.00      0.95      0.98        44\n",
      "\n",
      "        accuracy                           0.98       351\n",
      "       macro avg       0.98      0.98      0.98       351\n",
      "    weighted avg       0.98      0.98      0.98       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = client2.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels\n",
    "test_loss, test_accuracy = client2.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba124618-7ae9-43f6-b95f-af95f4fe3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[47  0  0  1  0  0  0]\n",
      " [ 0 35  0  0  0  0  0]\n",
      " [ 0  0 60  0  0  0  0]\n",
      " [ 0  0  0 45  0  5  0]\n",
      " [ 0  0  0  0 64  0  0]\n",
      " [ 0  0  0  0  0 50  0]\n",
      " [ 0  0  0  0  0  2 42]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09f025e7-8e94-414e-96ee-e68f42edd21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix2f.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00f6e705-25a5-4e65-bb9e-8a3d4272b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animal_Abuse': 0.9971509971509972, 'Arson': 1.0, 'Fight': 1.0, 'Normal': 0.9829059829059829, 'Riot': 1.0, 'Traffic_Accident': 0.98005698005698, 'Train_Accident': 0.9943019943019943}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    # True negatives are all the samples that are not our current GT class (not the current row) \n",
    "    # and were not predicted as the current class (not the current column)\n",
    "    true_negatives = np.sum(np.delete(np.delete(cm, idx, axis=0), idx, axis=1))\n",
    "    \n",
    "    # True positives are all the samples of our current GT class that were predicted as such\n",
    "    true_positives = cm[idx, idx]\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = (true_positives + true_negatives) / np.sum(cm)\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9057be5a-f701-42f4-ad16-d5381888586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 47, Total Instances: 48\n",
      "Arson - True Positives: 35, Total Instances: 35\n",
      "Fight - True Positives: 60, Total Instances: 60\n",
      "Normal - True Positives: 45, Total Instances: 50\n",
      "Riot - True Positives: 64, Total Instances: 64\n",
      "Traffic_Accident - True Positives: 50, Total Instances: 50\n",
      "Train_Accident - True Positives: 42, Total Instances: 44\n",
      "{'Animal_Abuse': 0.9791666666666666, 'Arson': 1.0, 'Fight': 1.0, 'Normal': 0.9, 'Riot': 1.0, 'Traffic_Accident': 1.0, 'Train_Accident': 0.9545454545454546}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2c6be-e3d2-4b98-b889-092dbb5b822f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
