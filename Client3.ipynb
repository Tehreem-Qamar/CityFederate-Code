{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33771573-05df-4109-86b9-878babc0cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import flwr as fl\n",
    "# Load and compile Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf75d36-4a17-4f41-85c0-f8b9cb06791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c156b7-afe0-4c69-aaa0-56c0f195c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_data_dir = 'D:/TQ/Federated/3/train/'\n",
    "\n",
    "test_data_dir = 'D:/TQ/Federated/3/val/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa64b10-7877-477a-8c9e-6441a3ef7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Set the validation split percentage\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fb633-e595-4a3c-861a-a09b99386696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts in Training Samples:\n",
      "['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
      "Animal_Abuse: 40 samples\n",
      "Arson: 240 samples\n",
      "Fight: 880 samples\n",
      "Normal: 199 samples\n",
      "Riot: 89 samples\n",
      "Traffic_Accident: 160 samples\n",
      "Train_Accident: 136 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Counts in Training Samples:\")\n",
    "total_classes = sorted(os.listdir(train_data_dir))\n",
    "print(total_classes)\n",
    "for category in total_classes:\n",
    "    category_path = os.path.join(train_data_dir, category)\n",
    "    sample_count = len(os.listdir(category_path))\n",
    "    print(f\"{category}: {sample_count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a147d6-0056-4cf8-ac6a-abb71e30c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = sorted(os.listdir(train_data_dir))\n",
    "test_classes = sorted(os.listdir(test_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b577db-0e07-4e6a-b627-21b571271f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout layer with a dropout rate of 0.5\n",
    "outputs = Dense(7, activation='softmax')(x)  # Assuming binary classification\n",
    "\n",
    "# Create the full model\n",
    "model3 = Model(inputs, outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model3.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ce4684-b004-4235-9a7d-ed6d371a020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1397 images belonging to 7 classes.\n",
      "Found 347 images belonging to 7 classes.\n",
      "Found 475 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(225, 225),\n",
    "                                                   class_mode='categorical',\n",
    "                                                   classes=total_classes,\n",
    "                                                   subset='training',\n",
    "                                                   batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42)\n",
    "\n",
    "validgen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(225, 225),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=total_classes,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(225, 225),\n",
    "                                             class_mode='categorical',\n",
    "                                             classes=total_classes,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e9f4e-6c00-4526-aa6b-1d6a941f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0e1c1d-7cad-4e48-a3aa-a0ee579a7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "175/175 [==============================] - 44s 235ms/step - loss: 0.7614 - accuracy: 0.7602 - val_loss: 1.1199 - val_accuracy: 0.7032\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 34s 194ms/step - loss: 0.1744 - accuracy: 0.9556 - val_loss: 1.3120 - val_accuracy: 0.6916\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 35s 202ms/step - loss: 0.1101 - accuracy: 0.9771 - val_loss: 1.5218 - val_accuracy: 0.6484\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 0.0860 - accuracy: 0.9792 - val_loss: 1.5485 - val_accuracy: 0.7003\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 36s 207ms/step - loss: 0.0741 - accuracy: 0.9807 - val_loss: 1.9630 - val_accuracy: 0.6138\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(\n",
    "            traingen,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(traingen),\n",
    "            validation_data=validgen,\n",
    "            validation_steps=len(validgen),\n",
    "            callbacks=callbacks,\n",
    "            verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8a7e0d-b293-4ea9-85ad-5ccb73af7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"Client3_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc89279f-832a-498d-b009-ee7f8bfa08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/475 [==============================] - 13s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = model3.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf942fb-108b-4952-86ea-5e442dc3a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Test Loss: 0.3339509963989258\n",
      "Test Accuracy: 0.9263157844543457\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "test_loss, test_accuracy = model3.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ee29f4-21fb-4c83-9c07-b185fb881694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[ 10   0   0   0   0   0   0]\n",
      " [  0  51   1   8   0   0   0]\n",
      " [  0   0 207  13   0   0   0]\n",
      " [  0   0   2  45   0   3   0]\n",
      " [  0   0   0   7  54   0   0]\n",
      " [  0   0   0   1   0  39   0]\n",
      " [  0   0   0   3   0   0  31]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b90e194d-4ba0-407c-8a32-297f88d73c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animal_Abuse': 1.0, 'Arson': 0.9789473684210527, 'Fight': 0.9726315789473684, 'Normal': 0.8778947368421053, 'Riot': 0.9852631578947368, 'Traffic_Accident': 0.9852631578947368, 'Train_Accident': 0.9936842105263158}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    # True negatives are all the samples that are not our current GT class (not the current row) \n",
    "    # and were not predicted as the current class (not the current column)\n",
    "    true_negatives = np.sum(np.delete(np.delete(cm, idx, axis=0), idx, axis=1))\n",
    "    \n",
    "    # True positives are all the samples of our current GT class that were predicted as such\n",
    "    true_positives = cm2[idx, idx]\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = (true_positives + true_negatives) / np.sum(cm2)\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05a0582f-7229-444e-900b-e86f18625639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 10, Total Instances: 10\n",
      "Arson - True Positives: 51, Total Instances: 60\n",
      "Fight - True Positives: 207, Total Instances: 220\n",
      "Normal - True Positives: 45, Total Instances: 50\n",
      "Riot - True Positives: 54, Total Instances: 61\n",
      "Traffic_Accident - True Positives: 39, Total Instances: 40\n",
      "Train_Accident - True Positives: 31, Total Instances: 34\n",
      "{'Animal_Abuse': 1.0, 'Arson': 0.85, 'Fight': 0.9409090909090909, 'Normal': 0.9, 'Riot': 0.8852459016393442, 'Traffic_Accident': 0.975, 'Train_Accident': 0.9117647058823529}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm2[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm2[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "968bce04-5078-432e-9b24-e294962e2a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm2, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix3.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1759984-7d01-46f2-9134-13361b238461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"Client3_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f341f304-c55d-4fef-a24a-9b461f66d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      1.00      1.00        10\n",
      "           Arson       1.00      0.85      0.92        60\n",
      "           Fight       0.99      0.94      0.96       220\n",
      "          Normal       0.58      0.90      0.71        50\n",
      "            Riot       1.00      0.89      0.94        61\n",
      "Traffic_Accident       0.93      0.97      0.95        40\n",
      "  Train_Accident       1.00      0.91      0.95        34\n",
      "\n",
      "        accuracy                           0.92       475\n",
      "       macro avg       0.93      0.92      0.92       475\n",
      "    weighted avg       0.94      0.92      0.93       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a72fe5b1-87ce-4ecd-ac58-fda9a49b89ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "client3 = tf.keras.models.load_model('client3_30_fedavg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33405fb5-f3d2-4ad7-9fdf-6c29b3faf6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/475 [==============================] - 9s 17ms/step\n",
      "Test Loss: 0.5552966594696045\n",
      "Test Accuracy: 0.88210529088974\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      1.00      1.00        10\n",
      "           Arson       0.98      0.87      0.92        60\n",
      "           Fight       1.00      0.80      0.89       220\n",
      "          Normal       0.46      0.90      0.61        50\n",
      "            Riot       1.00      1.00      1.00        61\n",
      "Traffic_Accident       0.87      1.00      0.93        40\n",
      "  Train_Accident       1.00      0.91      0.95        34\n",
      "\n",
      "        accuracy                           0.87       475\n",
      "       macro avg       0.90      0.93      0.90       475\n",
      "    weighted avg       0.93      0.87      0.89       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = client3.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels\n",
    "test_loss, test_accuracy = client3.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66d9527a-45a2-4e69-8fc8-05b77335e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[ 10   0   0   0   0   0   0]\n",
      " [  0  52   0   8   0   0   0]\n",
      " [  0   1 176  42   0   1   0]\n",
      " [  0   0   0  45   0   5   0]\n",
      " [  0   0   0   0  61   0   0]\n",
      " [  0   0   0   0   0  40   0]\n",
      " [  0   0   0   3   0   0  31]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9944a6cd-154c-4069-9797-9140cd9211f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix3f.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c66f895f-cbe4-4a9f-8aa8-8676414a8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animal_Abuse': 1.0, 'Arson': 0.9810526315789474, 'Fight': 0.9073684210526316, 'Normal': 0.8778947368421053, 'Riot': 1.0, 'Traffic_Accident': 0.9873684210526316, 'Train_Accident': 0.9936842105263158}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    # True negatives are all the samples that are not our current GT class (not the current row) \n",
    "    # and were not predicted as the current class (not the current column)\n",
    "    true_negatives = np.sum(np.delete(np.delete(cm, idx, axis=0), idx, axis=1))\n",
    "    \n",
    "    # True positives are all the samples of our current GT class that were predicted as such\n",
    "    true_positives = cm[idx, idx]\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = (true_positives + true_negatives) / np.sum(cm)\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b24243ca-a628-4d0b-84b4-4fe53859b8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 10, Total Instances: 10\n",
      "Arson - True Positives: 52, Total Instances: 60\n",
      "Fight - True Positives: 176, Total Instances: 220\n",
      "Normal - True Positives: 45, Total Instances: 50\n",
      "Riot - True Positives: 61, Total Instances: 61\n",
      "Traffic_Accident - True Positives: 40, Total Instances: 40\n",
      "Train_Accident - True Positives: 31, Total Instances: 34\n",
      "{'Animal_Abuse': 1.0, 'Arson': 0.8666666666666667, 'Fight': 0.8, 'Normal': 0.9, 'Riot': 1.0, 'Traffic_Accident': 1.0, 'Train_Accident': 0.9117647058823529}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5f4fa-0a5d-45d7-9464-b6900ec88f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
