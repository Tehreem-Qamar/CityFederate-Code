{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33771573-05df-4109-86b9-878babc0cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import flwr as fl\n",
    "# Load and compile Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf75d36-4a17-4f41-85c0-f8b9cb06791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c156b7-afe0-4c69-aaa0-56c0f195c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_data_dir = 'D:/TQ/Federated/5/train/'\n",
    "\n",
    "test_data_dir = 'D:/TQ/Federated/5/val/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa64b10-7877-477a-8c9e-6441a3ef7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Set the validation split percentage\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fb633-e595-4a3c-861a-a09b99386696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts in Training Samples:\n",
      "['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
      "Animal_Abuse: 168 samples\n",
      "Arson: 101 samples\n",
      "Fight: 88 samples\n",
      "Normal: 199 samples\n",
      "Riot: 418 samples\n",
      "Traffic_Accident: 138 samples\n",
      "Train_Accident: 0 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Counts in Training Samples:\")\n",
    "total_classes = sorted(os.listdir(train_data_dir))\n",
    "print(total_classes)\n",
    "for category in total_classes:\n",
    "    category_path = os.path.join(train_data_dir, category)\n",
    "    sample_count = len(os.listdir(category_path))\n",
    "    print(f\"{category}: {sample_count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a147d6-0056-4cf8-ac6a-abb71e30c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = sorted(os.listdir(train_data_dir))\n",
    "test_classes = sorted(os.listdir(test_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b577db-0e07-4e6a-b627-21b571271f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Add dropout layer with a dropout rate of 0.5\n",
    "outputs = Dense(7, activation='softmax')(x)  # Assuming binary classification\n",
    "\n",
    "# Create the full model\n",
    "model5 = Model(inputs, outputs)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model5.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ce4684-b004-4235-9a7d-ed6d371a020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 893 images belonging to 7 classes.\n",
      "Found 219 images belonging to 7 classes.\n",
      "Found 292 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(225, 225),\n",
    "                                                   class_mode='categorical',\n",
    "                                                   classes=total_classes,\n",
    "                                                   subset='training',\n",
    "                                                   batch_size=BATCH_SIZE, \n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42)\n",
    "\n",
    "validgen = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(225, 225),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=total_classes,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(225, 225),\n",
    "                                             class_mode='categorical',\n",
    "                                             classes=total_classes,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e9f4e-6c00-4526-aa6b-1d6a941f5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0e1c1d-7cad-4e48-a3aa-a0ee579a7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 18s 137ms/step - loss: 0.8511 - accuracy: 0.7044 - val_loss: 1.2548 - val_accuracy: 0.5479\n",
      "Epoch 2/5\n",
      "112/112 [==============================] - 14s 123ms/step - loss: 0.2333 - accuracy: 0.9239 - val_loss: 1.7190 - val_accuracy: 0.4338\n",
      "Epoch 3/5\n",
      "112/112 [==============================] - 13s 120ms/step - loss: 0.1592 - accuracy: 0.9462 - val_loss: 1.5053 - val_accuracy: 0.5525\n",
      "Epoch 4/5\n",
      "112/112 [==============================] - 14s 123ms/step - loss: 0.1067 - accuracy: 0.9642 - val_loss: 1.5390 - val_accuracy: 0.5890\n",
      "Epoch 5/5\n",
      "112/112 [==============================] - 16s 142ms/step - loss: 0.0944 - accuracy: 0.9698 - val_loss: 1.7063 - val_accuracy: 0.5662\n"
     ]
    }
   ],
   "source": [
    "history = model5.fit(\n",
    "            traingen,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(traingen),\n",
    "            validation_data=validgen,\n",
    "            validation_steps=len(validgen),\n",
    "            callbacks=callbacks,\n",
    "            verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0714593d-9d90-4ddb-9430-d47a48e03fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"D:/TQ/Federated/Client5_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc89279f-832a-498d-b009-ee7f8bfa08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 6s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = model5.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbf942fb-108b-4952-86ea-5e442dc3a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Test Loss: 0.6739577054977417\n",
      "Test Accuracy: 0.9041095972061157\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "test_loss, test_accuracy = model5.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76ee29f4-21fb-4c83-9c07-b185fb881694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[40  0  0  2  0  0  0]\n",
      " [ 0 25  0  1  0  0  0]\n",
      " [ 0  0 22  0  0  0  0]\n",
      " [ 0  2  0 44  0  4  0]\n",
      " [ 0  1  0  6 98  0  0]\n",
      " [ 0  0  0  0  0 35  0]\n",
      " [ 0  0  0 12  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9e7ed0-05e7-4396-8788-cf2e956b7da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm2, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix5.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74fb4fc6-eb1e-497b-854a-1bddc68b755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 40, Total Instances: 42\n",
      "Arson - True Positives: 26, Total Instances: 26\n",
      "Fight - True Positives: 22, Total Instances: 22\n",
      "Normal - True Positives: 44, Total Instances: 50\n",
      "Riot - True Positives: 99, Total Instances: 105\n",
      "Traffic_Accident - True Positives: 35, Total Instances: 35\n",
      "Train_Accident - True Positives: 0, Total Instances: 12\n",
      "{'Animal_Abuse': 0.9523809523809523, 'Arson': 1.0, 'Fight': 1.0, 'Normal': 0.88, 'Riot': 0.9428571428571428, 'Traffic_Accident': 1.0, 'Train_Accident': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm2[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm2[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1759984-7d01-46f2-9134-13361b238461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save(\"Client5_Centralized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79e00b9d-9e7a-464b-a376-6f0f8ce3e063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "client5_center = tf.keras.models.load_model('Client5_Centralized.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "717dfff6-e0c4-4aa3-bb4c-7367b579898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 5s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = client5_center.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc2f0d7-6619-4a6e-8d3c-7ae36bffeaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Test Loss: 0.6849393248558044\n",
      "Test Accuracy: 0.9075342416763306\n",
      "Confusion Matrix Before Aggregation:\n",
      "[[40  0  0  2  0  0  0]\n",
      " [ 0 26  0  0  0  0  0]\n",
      " [ 0  0 22  0  0  0  0]\n",
      " [ 0  2  0 44  0  4  0]\n",
      " [ 0  3  0  3 99  0  0]\n",
      " [ 0  0  0  0  0 35  0]\n",
      " [ 0  0  0 11  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "test_loss, test_accuracy = client5_center.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "# Calculate the confusion matrix\n",
    "cm2 = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f341f304-c55d-4fef-a24a-9b461f66d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.95      0.98        42\n",
      "           Arson       0.84      1.00      0.91        26\n",
      "           Fight       1.00      1.00      1.00        22\n",
      "          Normal       0.73      0.88      0.80        50\n",
      "            Riot       0.99      0.94      0.97       105\n",
      "Traffic_Accident       0.90      1.00      0.95        35\n",
      "  Train_Accident       0.00      0.00      0.00        12\n",
      "\n",
      "        accuracy                           0.91       292\n",
      "       macro avg       0.78      0.83      0.80       292\n",
      "    weighted avg       0.88      0.91      0.89       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ba8503-637c-4fad-bb6a-ecdb670117fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:370: DeprecationWarning: non-integer arguments to randrange() have been deprecated since Python 3.10 and will be removed in a subsequent version\n",
      "  return self.randrange(a, b+1)\n"
     ]
    }
   ],
   "source": [
    "client5 = tf.keras.models.load_model('client5_30_fedavg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5045bb5-706b-45db-96fb-91e311715131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cslen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2616: DeprecationWarning: Please import `affine_transform` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  ndimage.interpolation.affine_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 5s 15ms/step\n",
      "Test Loss: 0.44485604763031006\n",
      "Test Accuracy: 0.9109588861465454\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Animal_Abuse       1.00      0.98      0.99        42\n",
      "           Arson       0.95      0.81      0.88        26\n",
      "           Fight       1.00      1.00      1.00        22\n",
      "          Normal       0.72      0.92      0.81        50\n",
      "            Riot       1.00      0.96      0.98       105\n",
      "Traffic_Accident       0.88      1.00      0.93        35\n",
      "  Train_Accident       1.00      0.17      0.29        12\n",
      "\n",
      "        accuracy                           0.92       292\n",
      "       macro avg       0.94      0.83      0.84       292\n",
      "    weighted avg       0.93      0.92      0.91       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = testgen.classes\n",
    "\n",
    "# Calculate predictions on the test data\n",
    "y_pred = client5.predict(testgen)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the predicted class labels\n",
    "test_loss, test_accuracy = client5.evaluate(testgen, steps=len(testgen), verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(classification_report(y_true, y_pred_labels, target_names=total_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfd92e79-4f38-480f-937b-5f5bd6c2396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Before Aggregation:\n",
      "[[ 41   0   0   1   0   0   0]\n",
      " [  0  21   0   4   0   1   0]\n",
      " [  0   0  22   0   0   0   0]\n",
      " [  0   0   0  46   0   4   0]\n",
      " [  0   1   0   3 101   0   0]\n",
      " [  0   0   0   0   0  35   0]\n",
      " [  0   0   0  10   0   0   2]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "print(\"Confusion Matrix Before Aggregation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b62acaec-8594-4c10-98fd-87079c6b58ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix written to confusion_matrix.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "categories = ['Animal_Abuse', 'Arson', 'Fight', 'Normal', 'Riot', 'Traffic_Accident', 'Train_Accident']\n",
    "df_cm = pd.DataFrame(cm, index=categories, columns=categories)\n",
    "\n",
    "# Write the confusion matrix DataFrame to an Excel file\n",
    "excel_writer = pd.ExcelWriter('D:/TQ/Federated/confusion_matrix.xlsx')\n",
    "# Create an Excel workbook and write the confusion matrix DataFrame to a sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Confusion Matrix'\n",
    "\n",
    "# Write the column names\n",
    "ws.append([''] + df_cm.columns.tolist())\n",
    "\n",
    "# Write the confusion matrix data\n",
    "for index, row in df_cm.iterrows():\n",
    "    ws.append([index] + row.tolist())\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save('D:/TQ/Federated/confusion_matrix5f.xlsx')\n",
    "\n",
    "print(\"Confusion matrix written to confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f34f8491-4675-42cd-9ba7-b5fb5990ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_Abuse - True Positives: 41, Total Instances: 42\n",
      "Arson - True Positives: 21, Total Instances: 26\n",
      "Fight - True Positives: 22, Total Instances: 22\n",
      "Normal - True Positives: 46, Total Instances: 50\n",
      "Riot - True Positives: 101, Total Instances: 105\n",
      "Traffic_Accident - True Positives: 35, Total Instances: 35\n",
      "Train_Accident - True Positives: 2, Total Instances: 12\n",
      "{'Animal_Abuse': 0.9761904761904762, 'Arson': 0.8076923076923077, 'Fight': 1.0, 'Normal': 0.92, 'Riot': 0.9619047619047619, 'Traffic_Accident': 1.0, 'Train_Accident': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# We will store the results in a dictionary for easy access later\n",
    "per_class_accuracies = {}\n",
    "\n",
    "# Calculate the accuracy for each one of our classes\n",
    "for idx, cls in enumerate(total_classes):\n",
    "    true_positives = cm[idx, idx]\n",
    "    \n",
    "    # Total instances of the current class\n",
    "    total_instances = np.sum(cm[idx, :])\n",
    "    \n",
    "    # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "    per_class_accuracies[cls] = true_positives / total_instances if total_instances > 0 else 0\n",
    "    print(f\"{cls} - True Positives: {true_positives}, Total Instances: {total_instances}\")\n",
    "\n",
    "print(per_class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754ac98-c328-4556-bbbe-33d6f6ca3374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
